\documentclass[10pt]{article}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[fleqn]{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage[ruled,linesnumbered,noend]{algorithm2e}
\usepackage{empheq}
\usepackage{float}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage[colorlinks=true,urlcolor=blue]{hyperref}

\title{Introduction to Machine Learning, Fall 2014 - Exercise session V}
\author{Rodion ``rodde'' Efremov \\ 013593012}

\begin{document}
 \maketitle

\color{blue}
\section*{Problem 1 (3 points)}
Consider the following two sets of 80 cars each: Set `A' consists of 10 Volvos, 25 Toyotas, and 45 Audis, while set `B' consists of 8 Volvos, 32 Toyotas, and 40 Audis. Which set do you intuitively think is more pure (that is, has lower impurity), and why? Compute the entropy, the Gini index, and the misclassification error for each of the two sets. According to these measures, which set is more pure? Could this phenomenon (conflict among the measures) happen if there were just two classes (two types of car) rather than three? Why, or why not?

\color{black}
To me, it seems that the set `A' is more pure than `B', for ``intervals'' in set `A' are more ``equal'' than in the set `B'.

The entropy of the set A is ($\log = \log_2$)
\begin{align*}
&-\frac{10}{80} \log \frac{10}{80} - \frac{25}{80} \log \frac{25}{80} - \frac{45}{80} \log \frac{45}{80} \\ 
&= \frac{1}{8}(\log 80 - \log 10) +\frac{5}{16} (\log 80 - \log 25) + \frac{9}{16} (\log 80 - \log 45) \\
 &\approx 0.375 + 0.524 + 0.467 \\
 &\approx 1.366.
\end{align*}

The entropy of the set B is
\begin{align*}
&-\frac{8}{80} \log \frac{8}{80} - \frac{32}{80} \log \frac{32}{80} - \frac{40}{80} \log \frac{40}{80} \\
&= \frac{1}{10} \log 10 + \frac{4}{10} (\log 80 - \log 32) + \frac{1}{2} \log 2 \\
&\approx 0.332+ 0.529 + 0.5 \\
&\approx 1.361.
\end{align*}

The Gini index of the set A is
\begin{align*}
&1 - \Bigg( \frac{10}{80} \Bigg)^2 - \Bigg( \frac{25}{80} \Bigg)^2 - \Bigg( \frac{45}{80}  \Bigg)^2 \\
&= 1 - (1 / 8)^2 - (5/16)^2 - (9/16)^2 \\
&\approx 1 - 0.016 - 0.098 - 0.316 \\
&\approx 0.570.
\end{align*}

The Gini index of the set B is
\begin{align*}
&1 - \Bigg( \frac{8}{80} \Bigg)^2 - \Bigg( \frac{32}{80} \Bigg)^2 - \Bigg( \frac{40}{80} \Bigg)^2 \\
&\approx 1 - 0.01 - 0.16 - 0.25 \\
&\approx 0.58.
\end{align*}

The classification error of the set A is
\begin{align*}
1 - \frac{45}{80} = 1 - \frac{9}{16} = 0.4375.
\end{align*}

The classification error of the set B is
\begin{align*}
1 - \frac{40}{80} = 0.5.
\end{align*}

In summary:
\begin{table}[h]
\centering
\begin{tabular}[H]{|c||c|c|c|}
\hline
 & Entropy & Gini index & Classification error \\
 \hline
 A & 1.366 & 0.570 & 0.438 \\
 \hline
 B & 1.361 & 0.580 & 0.5 \\
 \hline
\end{tabular}
\end{table}
According to the above table, the set A is slightly more pure than B.

Suppose a set contains $N$ elements in total, and $M$ of them belong to one type of elements and $N - M$ to the other one. Now, all the impurity measure will attain their maximum value at around $M = \frac{N}{2}$, and all measures will be monotonically increasing on $[0, \frac{N}{2})$, and monotonically decreasing on $(\frac{N}{2}, N]$, so improvement in, say, Gini index will lead to improvement in classification error or entropy, and vice versa. (As can be seen in a figure of course slides.)

\color{blue}
\section*{Problem 2 (3 points)}
Consider a binary classification problem with the following set of attributes and attribute values:
\begin{itemize}
  \item Air conditioner = \{ Working, Broken \}
  \item Engine = \{ Good, Bad \}
  \item Mileage = \{ High, Medium, Low \}
  \item Rust = \{ Yes, No \}
\end{itemize}
Suppose a rule-based classifier produces the following rule set:
\begin{itemize}
  \item (Mileage = High) $\leftarrow$ (Value = Low)
  \item (Mileage = Low) $\leftarrow$ (Value = High)
  \item ((Air conditioner = Working) and (Engine = Good)) $\leftarrow$ (Value = High)
  \item ((Air conditioner = Working) and (Engine = Bad)) $\leftarrow$ (Value = Low)
  \item (Air conditioiner = Broken) $\leftarrow$ (Value = Low)
\end{itemize}
Given the above, answer the following:
\begin{enumerate}
  \item[(a)] Are the rules mutually exclusive?
  \color{black} Yes, they are. On each record, at most one rule is triggered.
  
  \color{blue}
  \item[(b)] Is the rule set exhaustive? 
  \color{black} Suppose that Mileage = Medium. This is not covered by two first rules, but it all boils down to the fact that Air conditioner will ``catch'' all the records regardless of the state of Engine. So, yes, the rule set is exhaustive.

  \color{blue}
  \item[(c)] Is ordering needed for this set of rules?
  \color{black} No, it doesn't appear that way: mileage is a good predictor of the value of a car, so it is justified to have the first two rules where they are.
  
  \color{blue}
  \item[(d)] Do you need a default class for the rule set?
  \color{black}
  No, we don't need that since the rules are exhaustive.
\end{enumerate}

\color{blue}
\section*{Problem 3 (3 points)}

\color{blue}
\section*{Problem 4 (15 points)}

\end{document}